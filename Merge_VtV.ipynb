{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fd861d4-3198-4bae-9baa-3b5e189f1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e05e3c-329e-4090-bbc7-d31c41aabcec",
   "metadata": {},
   "source": [
    "This section reads 2 VtV files and prepares them to be merged. method == 0 reads files that end with _single.txt, these are the single speaker transcriptions produced from videos where there is only 1 speaker. method != 0 reads files that end with _single_X.txt and _single_Y.txt, these are single speaker transcriptions produced by splitting the speakers from videos with 2 speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84667512-4ea5-4b3e-b752-e1f73ce3835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 0\n",
    "if method == 0: # Merge seperate transcriptions\n",
    "    directory = \"Transcripts/Study 2 (Fall2023)/VTV/\"\n",
    "    file_start = \"VtV36\"\n",
    "    \n",
    "    dfA = pd.read_csv(directory + \"single/\"+ file_start + \"A_single.txt\", sep=\"|\")\n",
    "    dfB = pd.read_csv(directory + \"single/\"+ file_start + \"B_single.txt\", sep=\"|\")\n",
    "else: # Merge pre split transcriptions\n",
    "    directory = \"Transcripts/Study 2 (Fall2023)/VTV/\"\n",
    "    file_start = \"VtV17\"\n",
    "    \n",
    "    dfA = pd.read_csv(directory + \"single/\"+ file_start + \"A_single_X.txt\", sep=\"|\")\n",
    "    dfB = pd.read_csv(directory + \"single/\"+ file_start + \"B_single_Y.txt\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2fc24b-cdd8-454a-8e05-b1d1b003b0cd",
   "metadata": {},
   "source": [
    "To merge, we select 2 timestamps in both transcriptions that have been manually determined to be identical in actual time. We then calculate the difference and subtract the difference from the first transcriptions file, which synchronizes the timestamps for both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f10629ff-b6c5-4e89-8450-cf34ba325fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA_time = 123.28999999999999\n",
    "dfB_time = 122.24000000000001\n",
    "difference = dfA_time - dfB_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd4e38e9-b598-4c75-ad26-84bb83b53643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA[\"Start Time\"] = dfA[\"Start Time\"] -difference\n",
    "dfA[\"End Time\"]= dfA[\"End Time\"] -difference\n",
    "dfA[\"Speaker\"] = \"Speaker 1\"\n",
    "dfB[\"Speaker\"] = \"Speaker 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a868b7-febd-4267-950c-6d1ab8bbc6ec",
   "metadata": {},
   "source": [
    "We can then merge both files and then sort by the start time of each line of speech. This produces a merged transcription that we can now save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcb006ec-3ee3-411e-a8fc-e00fb20fdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([dfA, dfB])\n",
    "df_new = df_new.sort_values(by=[\"Start Time\"])\n",
    "df_new.to_csv(directory + \"dyad/\"+ file_start + \"_dyad.txt\", index=False,sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f063d-f265-4425-a745-642e2f9a893e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
